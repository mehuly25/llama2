{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt3nRdMxbFZ4",
        "outputId": "3d2118f4-881c-4aeb-964d-1af283251233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /home/chakrabort/.local/lib/python3.12/site-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /home/chakrabort/.local/lib/python3.12/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
            "Requirement already satisfied: hstspreload in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
            "Requirement already satisfied: sniffio in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /home/chakrabort/.local/lib/python3.12/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /home/chakrabort/.local/lib/python3.12/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /home/chakrabort/.local/lib/python3.12/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "neUy33tVbbnX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "from googletrans import Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9dAn8zVfY-5"
      },
      "source": [
        "For the dataset \"gender_stereotypes_augmented_A_B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RHNNjk4BfDRj"
      },
      "outputs": [],
      "source": [
        "translator = Translator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KylZ-ui9bke_",
        "outputId": "cfa8e73c-1c84-4c1a-db6c-2cd9a53b4825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Translated everything including keys. Saved to: /home/chakrabort/Documents/Llama2/Dataset_Italian/gender_stereotypes_translated_it_with_keys.json\n"
          ]
        }
      ],
      "source": [
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset/gender_stereotypes_augmented_A_B.json\"\n",
        "output_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/gender_stereotypes_translated_it_with_keys.json\"\n",
        "\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ✅ Function to translate everything including keys\n",
        "def translate_all(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        new_dict = {}\n",
        "        for k, v in obj.items():\n",
        "            try:\n",
        "                # Translate key\n",
        "                if k.strip() in [\"(A)\", \"(B)\"]:\n",
        "                    new_key = k\n",
        "                else:\n",
        "                    new_key = translator.translate(k, src='en', dest='it').text\n",
        "\n",
        "                # Translate value\n",
        "                new_value = translate_all(v)\n",
        "                new_dict[new_key] = new_value\n",
        "            except Exception as e:\n",
        "                print(f\"Key translation failed for: {k} → {e}\")\n",
        "                new_dict[k] = translate_all(v)\n",
        "        return new_dict\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "        return [translate_all(item) for item in obj]\n",
        "\n",
        "    elif isinstance(obj, str):\n",
        "        if obj.strip() in [\"(A)\", \"(B)\"]:\n",
        "            return obj\n",
        "        try:\n",
        "            translated = translator.translate(obj, src=\"en\", dest=\"it\")\n",
        "            return translated.text if translated and translated.text else obj\n",
        "        except Exception as e:\n",
        "            print(f\"Value translation failed for: {obj[:50]}... → {e}\")\n",
        "            return obj\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# Perform full translation\n",
        "translated_data = translate_all(data)\n",
        "\n",
        "# Save translated file\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(translated_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Translated everything including keys. Saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the dataset \"refusal_data_A_B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_1.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_2.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_3.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_4.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_5.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_6.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_7.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_8.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_9.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_10.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_11.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_12.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_13.json (30 questions)\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_14.json (28 questions)\n",
            "\n",
            "✅ All done! 14 chunks created in '/home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks'\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "input_file = \"/home/chakrabort/Documents/Llama2/Dataset/refusal_data_A_B.json\"  # your full dataset\n",
        "output_dir = \"/home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks\"    # folder to save chunks\n",
        "chunk_size = 30                        # Questions per chunk\n",
        "\n",
        "# === LOAD DATA ===\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# === SPLIT INTO CHUNKS ===\n",
        "chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
        "\n",
        "# === CREATE OUTPUT FOLDER ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === SAVE EACH CHUNK ===\n",
        "for i, chunk in enumerate(chunks):\n",
        "    filename = f\"{output_dir}/refusal_data_chunk_{i + 1}.json\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(chunk, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"✅ Saved: {filename} ({len(chunk)} questions)\")\n",
        "\n",
        "print(f\"\\n✅ All done! {len(chunks)} chunks created in '{output_dir}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: deep-translator in /home/chakrabort/.local/lib/python3.12/site-packages (1.11.4)\n",
            "Requirement already satisfied: tqdm in /home/chakrabort/.local/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/chakrabort/.local/lib/python3.12/site-packages (from deep-translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/chakrabort/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.1.31)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install deep-translator tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import sys\n",
        "from deep_translator import GoogleTranslator\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔢 Total translatable strings (keys + values): 168\n",
            "🔁 Translating:   0%|          | 0/168 [00:00<?, ?item/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔁 Translating:  17%|█▋        | 28/168 [09:56<49:42, 21.31s/item]\n",
            "\n",
            "✅ Translation complete! Output saved to: /home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_chunks/refusal_data_14_IT.json\n"
          ]
        }
      ],
      "source": [
        "# === CONFIG ===\n",
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset/refusal_data_chunks/refusal_data_chunk_14.json\"\n",
        "output_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_chunks/refusal_data_14_IT.json\"\n",
        "\n",
        "# === TRANSLATOR ===\n",
        "translator = GoogleTranslator(source='en', target='it')\n",
        "\n",
        "# === SAFE TRANSLATE FUNCTION ===\n",
        "def safe_translate(text, delay=5):\n",
        "    try:\n",
        "        time.sleep(delay)\n",
        "        return translator.translate(text)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation failed for '{text[:30]}': {e}\")\n",
        "        return text\n",
        "\n",
        "# === COUNT STRINGS TO TRACK PROGRESS ===\n",
        "def count_strings(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return sum(count_strings(k) for k in obj.keys()) + sum(count_strings(v) for v in obj.values())\n",
        "    elif isinstance(obj, list):\n",
        "        return sum(count_strings(i) for i in obj)\n",
        "    elif isinstance(obj, str):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# === TRANSLATE ALL (WITH KEYS + VALUES) ===\n",
        "def translate_all(obj, pbar=None):\n",
        "    if isinstance(obj, dict):\n",
        "        new_dict = {}\n",
        "        for k, v in obj.items():\n",
        "            # Translate key\n",
        "            try:\n",
        "                new_key = k if k.strip() in [\"(A)\", \"(B)\"] else safe_translate(k)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Key translation failed for: {k} → {e}\")\n",
        "                new_key = k\n",
        "\n",
        "            # Translate value recursively\n",
        "            try:\n",
        "                new_dict[new_key] = translate_all(v, pbar)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Value translation failed for key '{new_key}' → {e}\")\n",
        "                new_dict[new_key] = v\n",
        "        return new_dict\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "        return [translate_all(i, pbar) for i in tqdm(obj, desc=\"📚 Translating list\", leave=False, file=sys.stdout)]\n",
        "\n",
        "    elif isinstance(obj, str):\n",
        "        if obj.strip() in [\"(A)\", \"(B)\"]:\n",
        "            return obj\n",
        "        try:\n",
        "            translated = safe_translate(obj)\n",
        "            if pbar:\n",
        "                pbar.update(1)\n",
        "            return translated\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Value translation failed for: {obj[:40]}... → {e}\")\n",
        "            return obj\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# === LOAD INPUT JSON ===\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# === COUNT FOR PROGRESS TRACKING ===\n",
        "total_strings = count_strings(data)\n",
        "print(f\"🔢 Total translatable strings (keys + values): {total_strings}\")\n",
        "\n",
        "# === TRANSLATE WITH PROGRESS BAR ===\n",
        "with tqdm(total=total_strings, desc=\"🔁 Translating\", unit=\"item\", file=sys.stdout) as pbar:\n",
        "    translated_data = translate_all(data, pbar)\n",
        "\n",
        "# === SAVE OUTPUT ===\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(translated_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Translation complete! Output saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Merged 14 chunks correctly into: /home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_chunks/refusal_data_IT_merged.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Folder where chunks are stored\n",
        "folder_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_chunks\"\n",
        "\n",
        "# Correctly sort files by extracting the number from filename\n",
        "file_names = sorted(\n",
        "    [f for f in os.listdir(folder_path) if f.endswith(\".json\")],\n",
        "    key=lambda x: int(re.search(r'refusal_data_(\\d+)_IT\\.json', x).group(1))\n",
        ")\n",
        "\n",
        "merged_data = []\n",
        "\n",
        "# Merge files in proper order\n",
        "for file_name in file_names:\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        chunk_data = json.load(f)\n",
        "        merged_data.extend(chunk_data)\n",
        "\n",
        "# Save the merged file\n",
        "output_path = os.path.join(folder_path, \"refusal_data_IT_merged.json\")\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Merged {len(file_names)} chunks correctly into: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Keys updated and saved to: /home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_final.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Path to the merged Italian file\n",
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_merged.json\"\n",
        "output_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/refusal_data_IT_final.json\"\n",
        "\n",
        "# Load the merged dataset\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Rename the keys in each dictionary\n",
        "for entry in data:\n",
        "    if \"Risposta_matching_behavior\" in entry:\n",
        "        entry[\"risposta_correlata\"] = entry.pop(\"Risposta_matching_behavior\")\n",
        "    if \"Risposta_not_matching_behavior\" in entry:\n",
        "        entry[\"risposta_non_correlata\"] = entry.pop(\"Risposta_not_matching_behavior\")\n",
        "\n",
        "# Save the updated dataset\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Keys updated and saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In5WFT1ffjCH"
      },
      "source": [
        "For the dataset \"stereotype_data_A_B_subset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/race.json\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/gender.json\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/profession.json\n",
            "✅ Saved: /home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/religion.json\n"
          ]
        }
      ],
      "source": [
        "# Dividing into seperate jsons\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Path to input JSON file\n",
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset/stereotype_data_A_B_subset.json\"\n",
        "\n",
        "# Output directory\n",
        "output_dir = \"/home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the full JSON data\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Save each top-level key's content to its own file\n",
        "for key in data:\n",
        "    output_path = os.path.join(output_dir, f\"{key}.json\")\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
        "        json.dump(data[key], out_file, ensure_ascii=False, indent=2)\n",
        "    print(f\"✅ Saved: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deep-translator in /home/chakrabort/.local/lib/python3.12/site-packages (1.11.4)\n",
            "Requirement already satisfied: tqdm in /home/chakrabort/.local/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/chakrabort/.local/lib/python3.12/site-packages (from deep-translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/chakrabort/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/chakrabort/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/chakrabort/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.1.31)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install deep-translator tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import sys\n",
        "from deep_translator import GoogleTranslator\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔢 Total translatable strings (keys + values): 1200\n",
            "🔁 Translating:  17%|█▋        | 200/1200 [1:10:25<5:52:09, 21.13s/item]\n",
            "\n",
            "✅ Translation complete! Output saved to: /home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/profession_IT_chunks/profession_IT_chunk_4.json\n"
          ]
        }
      ],
      "source": [
        "# === CONFIG ===\n",
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/profession_chunks/profession_chunk_4.json\"\n",
        "output_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/profession_IT_chunks/profession_IT_chunk_4.json\"\n",
        "\n",
        "# === TRANSLATOR ===\n",
        "translator = GoogleTranslator(source='en', target='it')\n",
        "\n",
        "# === SAFE TRANSLATE FUNCTION ===\n",
        "def safe_translate(text, delay=5):\n",
        "    try:\n",
        "        time.sleep(delay)\n",
        "        return translator.translate(text)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation failed for '{text[:30]}': {e}\")\n",
        "        return text\n",
        "\n",
        "# === COUNT STRINGS TO TRACK PROGRESS ===\n",
        "def count_strings(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return sum(count_strings(k) for k in obj.keys()) + sum(count_strings(v) for v in obj.values())\n",
        "    elif isinstance(obj, list):\n",
        "        return sum(count_strings(i) for i in obj)\n",
        "    elif isinstance(obj, str):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# === TRANSLATE ALL (WITH KEYS + VALUES) ===\n",
        "def translate_all(obj, pbar=None):\n",
        "    if isinstance(obj, dict):\n",
        "        new_dict = {}\n",
        "        for k, v in obj.items():\n",
        "            # Translate key\n",
        "            try:\n",
        "                new_key = k if k.strip() in [\"(A)\", \"(B)\"] else safe_translate(k)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Key translation failed for: {k} → {e}\")\n",
        "                new_key = k\n",
        "\n",
        "            # Translate value recursively\n",
        "            try:\n",
        "                new_dict[new_key] = translate_all(v, pbar)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Value translation failed for key '{new_key}' → {e}\")\n",
        "                new_dict[new_key] = v\n",
        "        return new_dict\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "        return [translate_all(i, pbar) for i in tqdm(obj, desc=\"📚 Translating list\", leave=False, file=sys.stdout)]\n",
        "\n",
        "    elif isinstance(obj, str):\n",
        "        if obj.strip() in [\"(A)\", \"(B)\"]:\n",
        "            return obj\n",
        "        try:\n",
        "            translated = safe_translate(obj)\n",
        "            if pbar:\n",
        "                pbar.update(1)\n",
        "            return translated\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Value translation failed for: {obj[:40]}... → {e}\")\n",
        "            return obj\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# === LOAD INPUT JSON ===\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# === COUNT FOR PROGRESS TRACKING ===\n",
        "total_strings = count_strings(data)\n",
        "print(f\"🔢 Total translatable strings (keys + values): {total_strings}\")\n",
        "\n",
        "# === TRANSLATE WITH PROGRESS BAR ===\n",
        "with tqdm(total=total_strings, desc=\"🔁 Translating\", unit=\"item\", file=sys.stdout) as pbar:\n",
        "    translated_data = translate_all(data, pbar)\n",
        "\n",
        "# === SAVE OUTPUT ===\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(translated_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Translation complete! Output saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Done! Created 5 chunk files in /home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/profession_chunks\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "input_path = \"/home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/profession.json\"  # replace with your file path\n",
        "output_dir = \"/home/chakrabort/Documents/Llama2/Dataset/stereotype_data_chunks/profession_chunks\"         # replace with your output directory\n",
        "chunk_size = 200\n",
        "\n",
        "# === CREATE OUTPUT DIRECTORY IF NOT EXISTS ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === LOAD JSON FILE ===\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# === SPLIT INTO CHUNKS AND SAVE ===\n",
        "for i in range(0, len(data), chunk_size):\n",
        "    chunk = data[i:i + chunk_size]\n",
        "    chunk_filename = f\"profession_chunk_{i // chunk_size + 1}.json\"\n",
        "    chunk_path = os.path.join(output_dir, chunk_filename)\n",
        "    with open(chunk_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(chunk, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Done! Created {len(data) // chunk_size + (1 if len(data) % chunk_size else 0)} chunk files in {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Merged 5 chunks. Total entries: 827\n",
            "📄 Saved to: /home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/profession_IT_chunks/profession_IT.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "folder_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/profession_IT_chunks\"  # change this to your actual path\n",
        "output_path = os.path.join(folder_path, \"profession_IT.json\")\n",
        "\n",
        "# === FILE LIST IN ORDER ===\n",
        "file_names = [\n",
        "    \"profession_IT_chunk_1.json\",\n",
        "    \"profession_IT_chunk_2.json\",\n",
        "    \"profession_IT_chunk_3.json\",\n",
        "    \"profession_IT_chunk_4.json\",\n",
        "    \"profession_IT_chunk_5.json\"\n",
        "]\n",
        "\n",
        "# === MERGE ===\n",
        "merged_data = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        chunk = json.load(f)\n",
        "        merged_data.extend(chunk)\n",
        "\n",
        "# === SAVE MERGED FILE ===\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Merged {len(file_names)} chunks. Total entries: {len(merged_data)}\")\n",
        "print(f\"📄 Saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ File unificato salvato come: /home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load each JSON file from the specified directory\n",
        "with open(\"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/race_IT.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    race_data = json.load(f)\n",
        "\n",
        "with open(\"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/gender_IT.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    gender_data = json.load(f)\n",
        "\n",
        "with open(\"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/profession_IT.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    profession_data = json.load(f)\n",
        "\n",
        "with open(\"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT_chunks/religion_IT.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    religion_data = json.load(f)\n",
        "\n",
        "# Merge into a single dictionary with Italian keys\n",
        "merged_data = {\n",
        "    \"razza\": race_data,\n",
        "    \"genere\": gender_data,\n",
        "    \"professione\": profession_data,\n",
        "    \"religione\": religion_data\n",
        "}\n",
        "\n",
        "# Save the merged JSON\n",
        "output_path = \"/home/chakrabort/Documents/Llama2/Dataset_Italian/stereotype_data_IT.json\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ File unificato salvato come: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05f2f900f6b847ac884e1ae5dd7c80ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479c7ee27bb24ee68dba0f58824f7519": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb2ae8239f44d28a4bc1f26bccfbb03",
            "placeholder": "​",
            "style": "IPY_MODEL_83c5b031660943ab8499a27cff640940",
            "value": "🔁 Translating:   0%"
          }
        },
        "4cb2ae8239f44d28a4bc1f26bccfbb03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52aaab1639f9485485608dfac66dff34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5667ea17ba0244f3972d9326015aec17",
            "max": 8686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98fa7a552a174d3ea2265a7d52d6902b",
            "value": 0
          }
        },
        "544caadf52964dba9b55cc30b049092c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5667ea17ba0244f3972d9326015aec17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c5b031660943ab8499a27cff640940": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98fa7a552a174d3ea2265a7d52d6902b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3839cf6f2994feba3e06cd4e2f8bdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_479c7ee27bb24ee68dba0f58824f7519",
              "IPY_MODEL_52aaab1639f9485485608dfac66dff34",
              "IPY_MODEL_fff1ed2fb4734cf6a91938251e7b200e"
            ],
            "layout": "IPY_MODEL_544caadf52964dba9b55cc30b049092c"
          }
        },
        "e32133c2502c40dda081b8140db80e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff1ed2fb4734cf6a91938251e7b200e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32133c2502c40dda081b8140db80e10",
            "placeholder": "​",
            "style": "IPY_MODEL_05f2f900f6b847ac884e1ae5dd7c80ef",
            "value": " 0/8686 [00:01&lt;?, ?item/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
